{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two minute Summary: Region-based Convolutional Neural Network (RCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is R-CNN?\n",
    "\n",
    "Region-based Convolutional Neural Networks or R-CNNs are the original tree from which the Fast, Faster, Mask R-CNN models have branched off. Traditional R-CNNs employed a very intuitive approach to a traditional CNN, converting the model from an image classification tool to an object detection tool. \n",
    "\n",
    "### But... HOW?\n",
    "\n",
    "#### Step 1\n",
    "\n",
    "Essentially, R-CNN will build a whole bunch of bounding boxes of different sizes and will try grouping adject pixels based on their texture, color or intensity to identify an object. The generally accepted practice is to create ~2000 of these **region proposals** (i.e. bounding boxes) for each image. This is known as the [**Selective Search Process**](http://www.cs.cornell.edu/courses/cs7670/2014sp/slides/VisionSeminar14.pdf). \n",
    "The image below highlights the selective search process conducted on some images!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./kaggle_rsna/research/assets_deep_learning_research/SelectiveSearch.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "Run a CNN on top of each of these ~2000 region proposals. *(Easier said than done, creating the 2000 regions and then 2000 CNNs on top of these regions is very computationally heavy, this is a downside of the R-CNN model)*\n",
    "\n",
    "#### Step 3\n",
    "The output form each of the CNNS is then fed into a Support Vector Machine (SVM) which will classify the regions, therefore we'll know if a region has found a sheep or a plane or a chair. \n",
    "\n",
    "#### Step 4\n",
    "Now we've found these regions we can use a linear regressor to tighten the bounding box of the obejct to make it as accurate as possible.\n",
    "\n",
    "Below is an image which higlights the these 4 steps in action:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./kaggle_rsna/research/assets_deep_learning_research/RCNN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation - Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nabeel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plot\n",
    "import pylab\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import glob\n",
    "import pylab\n",
    "import pydicom\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up directory\n",
    "\n",
    "wd = os.getcwd()\n",
    "\n",
    "input_dir = os.path.join(wd,'input')\n",
    "\n",
    "image_input_dir = os.path.join(input_dir,'stage_1_train_images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
