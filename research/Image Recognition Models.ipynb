{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick summary of the evolution of all things CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ive been reading a lot about the growth of convoluted neural nets and how it has been built on and grown to become a faster and more accurate image classification and object detection tool. Here is a two minute summary of the following algorithms, to help provide a conceptual overview of how they work at a high level:\n",
    "    \n",
    "    1) Convoluted Neural Net\n",
    "    2) Regional Convoluted Neural Net\n",
    "    3) Fast Regional Convoluted Neural Net\n",
    "    4) Faster Regional Convoluted Neural Net\n",
    "    5) Mask Regional Convoluted Neural Net\n",
    "    \n",
    "Thankfully the creators of these algorithms were not overly creative with their naming convention which makes it a lot easier to understand each iteration and which one is the *fastest.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two minute Summary:  Convolutional Neural Network (RCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two minute Summary: Region-based Convolutional Neural Network (RCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is R-CNN?\n",
    "\n",
    "Region-based Convolutional Neural Networks or R-CNNs are the original tree from which the Fast, Faster, Mask R-CNN models have branched off. Traditional R-CNNs employed a very intuitive approach to a traditional CNN, converting the model from an image classification tool to an object detection tool. \n",
    "\n",
    "### But... HOW?\n",
    "\n",
    "#### Step 1\n",
    "\n",
    "Essentially, R-CNN will build a whole bunch of bounding boxes of different sizes and will try grouping adject pixels based on their texture, color or intensity to identify an object. The generally accepted practice is to create ~2000 of these **region proposals** (i.e. bounding boxes) for each image. This is known as the [**Selective Search Process**](http://www.cs.cornell.edu/courses/cs7670/2014sp/slides/VisionSeminar14.pdf). \n",
    "The image below highlights the selective search process conducted on some images!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./kaggle_rsna/research/assets_deep_learning_research/SelectiveSearch.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "Run a CNN on top of each of these ~2000 region proposals. *(Easier said than done, creating the 2000 regions and then 2000 CNNs on top of these regions is very computationally heavy, this is a downside of the R-CNN model)*\n",
    "\n",
    "#### Step 3\n",
    "The output form each of the CNNS is then fed into a Support Vector Machine (SVM) which will classify the regions, therefore we'll know if a region has found a sheep or a plane or a chair. \n",
    "\n",
    "#### Step 4\n",
    "Now we've found these regions we can use a linear regressor to tighten the bounding box of the obejct to make it as accurate as possible.\n",
    "\n",
    "Below is an image which higlights the these 4 steps in action:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./kaggle_rsna/research/assets_deep_learning_research/RCNN.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
