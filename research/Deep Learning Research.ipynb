{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notes are based on 'Neural networks and deep learning' by Michael Nielsen, which can be found for free [here](http://neuralnetworksanddeeplearning.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What is a perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perceptron is a type of neuron in a neural network. They were used a lot in the past, but today it is more common to use other models of artificial neurons.\n",
    "\n",
    "They take several binary inputs $x_1, x_2, \\ldots, x_n$ and produce a single binary output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets_deep_learning_research/perceptron.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each input has an associated weight, $w$. The neuron's output is determined by whether the weighted sum is greather than some threshold value. \n",
    "\n",
    "Let $w_1, w_2, \\ldots, w_j$ be a vecotr of weights. Let $x_1, x_2, \\ldots, w_j$ be a vector of inputs to the neuron. Then the output of the neuron is described by the following formula:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  \\mbox{output} & = & \\left\\{ \\begin{array}{ll}\n",
    "      0 & \\mbox{if } \\sum_j w_j x_j \\leq \\mbox{ threshold} \\\\\n",
    "      1 & \\mbox{if } \\sum_j w_j x_j > \\mbox{ threshold}\n",
    "      \\end{array} \\right.\n",
    "\\tag{1}\\end{eqnarray}$$\n",
    "\n",
    "These vectors of weights and the threshold value are altered to create different models of decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What notation is more commonly used when describing how neurons work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted sum $\\sum_j w_j x_j$ is written as the dot product $w \\cdot x \\equiv \\sum_j w_j x_j$, where $w$ and $x$ are vectors whose components are the weights and inputs, respectively.\n",
    "\n",
    "The threshold is replaced by what is called the perceptron's *bias*, $b \\equiv -\\text{threshold}$. The bias is a measure of how easy it is for a perceptron to output $1$ (i.e. how easy it is to get a perceptron to *fire*). If the bias is large and positive, it is easy for the perceptron to output a $1$. If the bias is very negative, then it is difficult for the perceptron to output a $1$.\n",
    "\n",
    "Thus, the formula for the output of the perceptron is replaced with:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "  \\mbox{output} = \\left\\{ \n",
    "    \\begin{array}{ll} \n",
    "      0 & \\mbox{if } w\\cdot x + b \\leq 0 \\\\\n",
    "      1 & \\mbox{if } w\\cdot x + b > 0\n",
    "    \\end{array}\n",
    "  \\right.\n",
    "\\tag{2}\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a sigmoid neuron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks learn by making changes to the weights and biases of the network. If a small change in weights or biases meant that it produced a small change in output, then we could figure out how to alter the weights and biases to get closer to correctly predicting some input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why add more layers in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deeper layers allow for the network to model increasingly abstract and complex decisions.\n",
    "\n",
    "In the below example, the first layer of the neural network is making simple decisions by weighing up the input evidence. The second layer is weighing up decisions made by the first layer, making more complex and abstract decisions than the first layer itself. The third layers is making even more complex and abstract decisions still."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\assets_deep_learning_research\\perceptron_layers.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
